{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["7dLwFdlWDQmR","MD1xb12DuGuW","zXB0BmMYt6rq","VW-bsDLsp2Km","eZ3Z0KIv89FM","D9HfjCwQ9MmQ","dOtn3vwxpjI5"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"bH-xEOkcp-y9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f12ff687-1931-494f-dc59-5348ac3e5283","executionInfo":{"status":"ok","timestamp":1674839618194,"user_tz":-60,"elapsed":22306,"user":{"displayName":"Michele Carlo La Greca","userId":"08422419523344327391"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Packages"],"metadata":{"id":"7dLwFdlWDQmR"}},{"cell_type":"markdown","source":["## Download packages"],"metadata":{"id":"MD1xb12DuGuW"}},{"cell_type":"code","source":["!pip install split_folders"],"metadata":{"id":"6ByCbXPXEiGE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674839641633,"user_tz":-60,"elapsed":5579,"user":{"displayName":"Michele Carlo La Greca","userId":"08422419523344327391"}},"outputId":"2fdfd004-e994-4a2f-d572-823ac00521b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting split_folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split_folders\n","Successfully installed split_folders-0.5.1\n"]}]},{"cell_type":"markdown","source":["## Importing packages"],"metadata":{"id":"zXB0BmMYt6rq"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import shutil \n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","from PIL import Image\n","from zipfile import ZipFile, error\n","from tqdm import tqdm\n","from pathlib import Path\n","import splitfolders\n","import math\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers"],"metadata":{"id":"DRoXAjcRuGG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"metadata":{"id":"sSx1soaDuKvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","import logging\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","tf.get_logger().setLevel('INFO')\n","tf.autograph.set_verbosity(0)\n","\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.get_logger().setLevel('ERROR')\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"],"metadata":{"id":"ESL6-_i9uMeV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating data"],"metadata":{"id":"VW-bsDLsp2Km"}},{"cell_type":"code","source":["initial_zip_path = r'/content/drive/MyDrive/Courses/Applied AI for Biomedicine/Project/train_set.zip'\n","initial_folder_path = r'/content/drive/MyDrive/Courses/Applied AI for Biomedicine/Project/data'\n","csv_path = r'/content/drive/MyDrive/Courses/Applied AI for Biomedicine/Project/data/train/labels_train.csv'\n","csv2_path = r'/content/drive/MyDrive/Courses/Applied AI for Biomedicine/Project/data/labels_train.csv'\n","train_path = r'/content/drive/MyDrive/Courses/Applied AI for Biomedicine/Project/data/train'\n","project_path = r'/content/drive/MyDrive/Courses/Applied AI for Biomedicine/Project'"],"metadata":{"id":"2f7g9VlRuFaA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preliminary"],"metadata":{"id":"eZ3Z0KIv89FM"}},{"cell_type":"markdown","source":["We unzip the data."],"metadata":{"id":"k7DfrXDDOAVY"}},{"cell_type":"code","source":["with ZipFile(initial_zip_path) as zf:\n","  for member in tqdm(zf.infolist(), desc='Extracting '):\n","    try:\n","      zf.extract(member, initial_folder_path)\n","    except error as e:\n","      pass\n","  # Close the file\n","  zf.close()"],"metadata":{"id":"-vOvt1AStXU6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0612637f-895a-4f03-d0be-683a1d47496b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Extracting : 100%|██████████| 15471/15471 [02:58<00:00, 86.63it/s] \n"]}]},{"cell_type":"markdown","source":["After the unzip, we have a folder 'data' where we have a folder 'train' with both all the images and the csv file for the targets. We move the csv file in the directory above, so that inside 'data' we have the csv file with the targets and the folder 'train' with the images."],"metadata":{"id":"GQP5StdX7qvX"}},{"cell_type":"code","source":["p = Path(csv_path).absolute()\n","parent_dir = p.parents[1]\n","p.rename(parent_dir / p.name)"],"metadata":{"id":"KeU6z9xc7qNu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7aff8a7-a3f6-4122-e48c-88f6b4670db5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('/content/drive/MyDrive/Courses/Applied AI for Biomedicine/Project/data/labels_train.csv')"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### Make train folder"],"metadata":{"id":"D9HfjCwQ9MmQ"}},{"cell_type":"markdown","source":["We count how many images and other docs we have in the train folder."],"metadata":{"id":"TIzvWpeQLfl_"}},{"cell_type":"code","source":["dir_path = train_path\n","count_img = 0\n","count_docs = 0\n","# Iterate directory\n","for path in os.listdir(dir_path):\n","    # check if current path is a file\n","    if os.path.isfile(os.path.join(dir_path, path)):\n","      if path.endswith(\".png\") or path.endswith(\".jpeg\"):\n","        count_img += 1\n","      if path.endswith(\".csv\"):\n","        count_docs += 1\n","print('Images count:', count_img, \". Docs count:\", count_docs)\n"],"metadata":{"id":"69aOsNv9KdwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We save the target from the csv file, skipping the first row since it is the head."],"metadata":{"id":"Gl-eCWJT81f3"}},{"cell_type":"code","source":["# Read the labels from ground truth except the header\n","df = pd.read_csv(csv2_path, names=['file','label'], skiprows=1)\n","df.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMs2zy3LyIn5","outputId":"17e85231-bb2f-4544-b61d-bedb2c90f0ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15470"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Extract the labels and store in a new data frame called labels\n","labels = df.sort_values('label')\n","\n","# Create a Python list of Unique labels in data frame labels\n","class_names = list(labels.label.unique())"],"metadata":{"id":"6L5j2yW_OcyS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We create for each class a folder inside the train folder, and then we move each image in the corresponding folder based on its class."],"metadata":{"id":"jBWQxSV9HwKo"}},{"cell_type":"code","source":["for name_class in class_names:\n","    os.makedirs(os.path.join(train_path, name_class))"],"metadata":{"id":"-2FgfM3gIN0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in class_names:                # I ->  class label names\n","  for c in list(df[df['label']== i]['file']):    # c  -> name of the individual image that have the i class\n","    # Creating path to the image\n","    get_image = os.path.join(train_path,c)\n","      # get_image to that path\n","    if not os.path.exists(train_path +'/'+i+'/'+c):\n","      # move the image to this path\n","      move_image = shutil.copy(get_image, train_path +'/'+i)"],"metadata":{"id":"76ZfHeDEzG-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We check the number of images in the new folders."],"metadata":{"id":"nY6d3JoT-gTa"}},{"cell_type":"code","source":["for i in class_names: \n","  dir_path = os.path.join(train_path, i)\n","  count = 0\n","  # Iterate directory\n","  for path in os.listdir(dir_path):\n","      # check if current path is a file\n","      if os.path.isfile(os.path.join(dir_path, path)):\n","        if path.endswith(\".png\") or path.endswith(\".jpeg\"):\n","          count += 1\n","  print(\"Class \", i, \" has \", count, \" images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRUkcM3WqvlW","outputId":"1c6463c9-6e11-4099-8e26-10bb4e9c3da0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class  N  has  9354  images\n","Class  P  has  4250  images\n","Class  T  has  1866  images\n"]}]},{"cell_type":"markdown","source":["We check if the images has been placed in the right folders and we count them."],"metadata":{"id":"BIzotFMw-pX2"}},{"cell_type":"code","source":["for i in class_names: \n","  count = 0\n","  for c in list(df[df['label']== i]['file']):\n","    if not os.path.exists(train_path +'/'+i+'/'+c):\n","      print(\"error\")\n","    else:\n","      count += 1\n","  print(\"Class \", i, \" has \", count, \" images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzqwpxBSohXf","outputId":"dce9bf67-2fed-47b7-8d0d-74eec0614576"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class  N  has  9354  images\n","Class  P  has  4250  images\n","Class  T  has  1866  images\n"]}]},{"cell_type":"markdown","source":["We delete the original images and we keep only the ones in the class folders."],"metadata":{"id":"Aju6qaEOHDK7"}},{"cell_type":"code","source":["dir_name = project_path\n","test = os.listdir(dir_name)\n","\n","for item in test:\n","    if item.endswith(\".png\") or item.endswith(\".jpeg\"):\n","        os.remove(os.path.join(dir_name, item))"],"metadata":{"id":"xa4aUEYyHBge"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Check sizes and number of images"],"metadata":{"id":"dOtn3vwxpjI5"}},{"cell_type":"markdown","source":["We count the number of images in each class folder."],"metadata":{"id":"_L5xrhgOkpwo"}},{"cell_type":"code","source":["for i in class_names: \n","  dir_path = os.path.join(train_path, i)\n","  count = 0\n","  path_size = 0\n","  # Iterate directory\n","  for path in os.listdir(dir_path):\n","      # check if current path is a file\n","      if os.path.isfile(os.path.join(dir_path, path)):\n","        count += 1\n","        path_size += os.path.getsize(os.path.join(dir_path, path))\n","  print(\"Class \", i, \" has \", count, \" images\", \"and the total size is:\", path_size*1e-9, \"GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrOtziwzktoF","outputId":"07f651ce-ff15-43e2-c65e-fe1caff2edad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class  N  has  9354  images and the total size is: 2.435105812 GB\n","Class  P  has  4250  images and the total size is: 1.183822803 GB\n","Class  T  has  1866  images and the total size is: 1.0162671840000002 GB\n"]}]},{"cell_type":"code","source":["def get_size(start_path = project_path):\n","    total_size = 0\n","    for dirpath, dirnames, filenames in os.walk(start_path):\n","        for f in filenames:\n","            fp = os.path.join(dirpath, f)\n","            # skip if it is symbolic link\n","            if not os.path.islink(fp):\n","                total_size += os.path.getsize(fp)\n","\n","    return total_size\n","\n","print(get_size(), 'bytes')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvGPhKI5ngJJ","outputId":"91d70f7f-1d1e-42fa-a5be-5c4ab18ff45e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8994285261 bytes\n"]}]}]}